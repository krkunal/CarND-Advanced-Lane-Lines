{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "2. Apply a distortion correction to raw images.\n",
    "3. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "4. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "5. Detect lane pixels and fit to find the lane boundary.\n",
    "6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "7. Warp the detected lane boundaries back onto the original image.\n",
    "8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "from collections import deque\n",
    "from operator import sub\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# Imports needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "## 2. Apply a distortion correction to raw images.\n",
    "\n",
    "def get_distortion_matrices(img_size):\n",
    "    # prepare object points for 9x6 chessboard\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "    # Arrays to store object points and image points from all the images\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Step through the list, search for chessboard corners, and populate objpoints & imgpoints\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "    # Save the camera calibration result for later use\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    pickle.dump( dist_pickle, open( \"camera_cal/wide_dist_pickle.p\", \"wb\" ))\n",
    "    \n",
    "    # return calibration matrix & distortion coeff\n",
    "    return mtx, dist\n",
    "\n",
    "# Function to undistort the image given the camera calibration parameters\n",
    "def undistort(img, mtx, dist):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "# Get calibration matrix and distortion coeff & Test undistortion on an image\n",
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "mtx, dist = get_distortion_matrices(img_size)\n",
    "dst = cv2.cvtColor(undistort(img, mtx, dist), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)\n",
    "plt.savefig('output_images/distortion_correction.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying distortion correction on example image\n",
    "# Get calibration matrix and distortion coeff & Test undistortion on an image\n",
    "img = cv2.imread('test_images/test3.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "mtx, dist = get_distortion_matrices(img_size)\n",
    "dst = cv2.cvtColor(undistort(img, mtx, dist), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Visualize undistortion\n",
    "plt.figure(figsize = (60,45))\n",
    "plt.imshow(dst)\n",
    "plt.savefig('output_images/Undistorted_example.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Use color transforms, gradients, etc., to create a thresholded binary image. Expects BGR image.\n",
    "\n",
    "def color_grad_pipeline(img, s_thresh=(200, 255), sx_thresh=(30, 90)):\n",
    "    img = np.copy(img)\n",
    "    width_x = img.shape[1]\n",
    "    height_y = img.shape[0]\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "\n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(sxbinary == 1) | (s_binary == 1)] = 1\n",
    "    # Define Region threshold for a triangular region having base as the bottom of the image & height until the middle of the image\n",
    "    left_bottom = (0, height_y)\n",
    "    right_bottom = (width_x, height_y)\n",
    "    apex = (width_x / 2.0, height_y / 1.75)\n",
    "\n",
    "    fit_left = np.polyfit((left_bottom[0], apex[0]), (left_bottom[1], apex[1]), 1)\n",
    "    fit_right = np.polyfit((right_bottom[0], apex[0]), (right_bottom[1], apex[1]), 1)\n",
    "    fit_bottom = np.polyfit((left_bottom[0], right_bottom[0]), (left_bottom[1], right_bottom[1]), 1)\n",
    "    # Region inside the triangle formed by the lines\n",
    "    XX, YY = np.meshgrid(np.arange(width_x), np.arange(height_y))\n",
    "    region_thresholds = (YY > (XX*fit_left[0] + fit_left[1])) & \\\n",
    "                        (YY > (XX*fit_right[0] + fit_right[1])) & \\\n",
    "                        (YY < (XX*fit_bottom[0] + fit_bottom[1]))\n",
    "    # Region threshold masking\n",
    "    combined_binary[~region_thresholds] = 0\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Applying Median Blur to smoothen out the pixels\n",
    "    blurred_binary = cv2.medianBlur(combined_binary, 3)\n",
    "\n",
    "    return color_binary, blurred_binary #combined_binary\n",
    "    \n",
    "\n",
    "image = cv2.imread('test_images/test5.jpg')\n",
    "color_result, combined_result = color_grad_pipeline(image)\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(40, 20))\n",
    "f.tight_layout()\n",
    "\n",
    "ax1.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "ax1.set_title('Original Image', fontsize=20)\n",
    "\n",
    "ax2.imshow(color_result)\n",
    "ax2.set_title('Pipeline Result', fontsize=20)\n",
    "\n",
    "ax3.imshow(combined_result)\n",
    "ax3.set_title('detected edges', fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig('output_images/test6_binary.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Apply a perspective transform to rectify binary image (\"birds-eye view\"). --- Functions to extract src points on the image\n",
    "\n",
    "# Calculate histogram along x\n",
    "def hist(img, start_pixel, end_pixel):\n",
    "    (height, width) = img.shape\n",
    "    start, end = height - end_pixel, height - start_pixel\n",
    "    roi_img = img[start:end, :]\n",
    "\n",
    "    histogram = np.sum(roi_img, axis=0)\n",
    "    return histogram\n",
    "\n",
    "# Get the source points for Perspective transform\n",
    "def find_perspective_xform_pts(image):\n",
    "    (height_y, width_x) = image.shape\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((image, image, image))\n",
    "    # get the number of iterations to find the lane lines with sliding window of height 5 in the bottom half of the image\n",
    "    n_iters = image.shape[0] // 10\n",
    "    src_rect_pts = []\n",
    "    # Taking the initial midpoint as the center of the image\n",
    "    midpoint = np.int(width_x // 2)\n",
    "    for iter in range(n_iters):\n",
    "        # Take a histogram of the sliding window in the image\n",
    "        histogram = hist(image, iter*5, (iter + 1)*5)\n",
    "        # Check if the max value of the histogram exceeds a threshold, in this case, 5\n",
    "        # print(np.amax(histogram[:midpoint]), np.amax(histogram[midpoint:]))\n",
    "        found_points = (np.amax(histogram[:midpoint]) >= 5) & (np.amax(histogram[midpoint:]) >= 5)\n",
    "        if found_points:\n",
    "            # Find the peak of the left and right halves of the histogram\n",
    "            # These will give points on the left and right lane lines\n",
    "            left_x = np.argmax(histogram[:midpoint])\n",
    "            right_x = np.argmax(histogram[midpoint:]) + midpoint\n",
    "            # Append the source rectangle points\n",
    "            src_rect_pts.append([left_x, height_y - iter*5])\n",
    "            src_rect_pts.append([right_x, height_y - iter*5])\n",
    "            # Move the mid point to the middle of the two identified pts\n",
    "            midpoint = (left_x + right_x) // 2\n",
    "    # Taking only the first and last pair. Need to shuffle the order of vertices\n",
    "    src_pts = src_rect_pts[:2] + src_rect_pts[-1:] + src_rect_pts[-2:-1]\n",
    "    return src_pts\n",
    "\n",
    "# Process the image based on lane line colors and the region of interest. Expects an BGR image\n",
    "def process_image(img):\n",
    "    # color_result, combined_binary = pipeline(img)\n",
    "    width_x = img.shape[1]\n",
    "    height_y = img.shape[0]\n",
    "    \n",
    "    # Here, I'm doing relatively simplistic processing for the purpose of masking and identifying the lane lines. This is done just for the purpose of identifying source points on the image. \n",
    "    # Apply mask on expected lane line colors- white & yellow\n",
    "    # White mask \n",
    "    lower_white = np.array([200,200,200])\n",
    "    upper_white = np.array([255,255,255])\n",
    "    white_mask = cv2.inRange(img, lower_white, upper_white)\n",
    "    # Yellow mask\n",
    "    lower_yellow = np.array([0,80,130])\n",
    "    upper_yellow = np.array([85,255,255])\n",
    "    yellow_mask = cv2.inRange(img, lower_yellow, upper_yellow)\n",
    "\n",
    "    lane_mask = white_mask + yellow_mask\n",
    "\n",
    "    img[lane_mask == 0] = [0, 0, 0]\n",
    "\n",
    "    # Define Region threshold for a triangular region having base as the bottom of the image & height until the middle of the image\n",
    "    left_bottom = (0, height_y)\n",
    "    right_bottom = (width_x, height_y)\n",
    "    apex = (width_x / 2.0, height_y / 1.7)\n",
    "\n",
    "    fit_left = np.polyfit((left_bottom[0], apex[0]), (left_bottom[1], apex[1]), 1)\n",
    "    fit_right = np.polyfit((right_bottom[0], apex[0]), (right_bottom[1], apex[1]), 1)\n",
    "    fit_bottom = np.polyfit((left_bottom[0], right_bottom[0]), (left_bottom[1], right_bottom[1]), 1)\n",
    "    # Region inside the triangle formed by the lines\n",
    "    XX, YY = np.meshgrid(np.arange(width_x), np.arange(height_y))\n",
    "    region_thresholds = (YY > (XX*fit_left[0] + fit_left[1])) & \\\n",
    "                        (YY > (XX*fit_right[0] + fit_right[1])) & \\\n",
    "                        (YY < (XX*fit_bottom[0] + fit_bottom[1]))\n",
    "    # Region threshold masking\n",
    "    img[~region_thresholds] = 0\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Applying Median Blur to smoothen out the pixels\n",
    "    blurred_gray = cv2.medianBlur(gray, 3)\n",
    "    return blurred_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image\n",
    "img = cv2.imread('test_images/test1.jpg')\n",
    "# Undistort the image\n",
    "undistorted_img = undistort(img, mtx, dist)\n",
    "\n",
    "combined_binary = process_image(undistorted_img)\n",
    "# plt.imshow(combined_binary)\n",
    "src_pts = find_perspective_xform_pts(combined_binary)\n",
    "print(src_pts)\n",
    "src_img = cv2.polylines(img, np.array([src_pts], dtype=int), True, (0, 0, 255), 5)\n",
    "plt.imshow(cv2.cvtColor(src_img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Apply a perspective transform to rectify binary image (\"birds-eye view\") ---- Find the perspective transform matrix and persist\n",
    "\n",
    "def get_perspective_matrices(img, src_pts, dst_pts):\n",
    "    # 1) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "    # 2) use cv2.warpPerspective() to warp the image to a top-down view\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    Minv = cv2.getPerspectiveTransform(dst_pts, src_pts)\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_NEAREST)\n",
    "    return warped, M, Minv\n",
    "\n",
    "def xform_perspective(img, xform_matrix):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    return cv2.warpPerspective(img, xform_matrix, img_size)\n",
    "    \n",
    "# Read in the saved camera matrix and distortion coefficients\n",
    "dist_pickle = pickle.load( open( \"camera_cal/wide_dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Read in test image\n",
    "# One set of perspective transform done on the image straight_lines1.jpg\n",
    "# img = cv2.imread('test_images/straight_lines1.jpg')\n",
    "# src_pts = np.float32([[260, 680], [1048, 680], [833, 550], [460, 550]])\n",
    "# dst_pts = np.float32([[360, 680], [948, 680], [933, 350], [360, 350]])\n",
    "\n",
    "img = cv2.imread('test_images/test1.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Undistort the image\n",
    "undistorted_img = undistort(img, mtx, dist)\n",
    "\n",
    "# Source points identified in previous step. The destination points are approximated based on judgement\n",
    "src_pts = np.float32([[281, 695], [1104, 695], [836, 530], [495, 530]])\n",
    "dst_pts = np.float32([[400, 700], [978, 700], [978, 300], [400, 300]])\n",
    "src_img = cv2.polylines(undistorted_img, np.array([src_pts], dtype=int), True, (0, 0, 255), 5)\n",
    "\n",
    "top_down, perspective_M, perspective_Minv = get_perspective_matrices(src_img, src_pts, dst_pts)\n",
    "\n",
    "# Save the perspective xform metrices for later use\n",
    "perspective_pickle = {}\n",
    "perspective_pickle[\"mtxM\"] = perspective_M\n",
    "perspective_pickle[\"mtxMinv\"] = perspective_Minv\n",
    "pickle.dump(perspective_pickle, open(\"camera_cal/perspective_pickle.p\", \"wb\" ))\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(cv2.cvtColor(src_img, cv2.COLOR_BGR2RGB))\n",
    "ax1.set_title('Original Image with Src Pts', fontsize=30)\n",
    "ax2.imshow(cv2.cvtColor(top_down, cv2.COLOR_BGR2RGB))\n",
    "ax2.set_title('Warped Image with Dest Pts', fontsize=30)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig('output_images/perspective_transform.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = cv2.imread('test_images/test1.jpg')\n",
    "undist_img = undistort(test1, mtx, dist)\n",
    "_, combined_binary = color_grad_pipeline(undist_img)\n",
    "# Read in the saved camera matrix and distortion coefficients\n",
    "perspective_pickle = pickle.load( open( \"camera_cal/perspective_pickle.p\", \"rb\" ) )\n",
    "perspective_M = perspective_pickle[\"mtxM\"]\n",
    "binary_warped = xform_perspective(combined_binary, perspective_M)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 10))\n",
    "ax1.imshow(binary_warped)\n",
    "ax2.imshow(cv2.cvtColor(undist_img, cv2.COLOR_BGR2RGB))\n",
    "ax3.imshow(combined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Detect lane pixels and fit to find the lane boundary.\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom three quarters of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//4:,:], axis=0)\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 50\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 30\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # # Draw the windows on the visualization image\n",
    "        # cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        # (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        # cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        # (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "\n",
    "        ### Identify the nonzero pixels in x and y within the window ###\n",
    "        win_y_mask = np.array((nonzeroy >= win_y_low) & (nonzeroy < win_y_high))\n",
    "        win_xleft_mask = np.array((nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high))\n",
    "        win_xright_mask = np.array((nonzerox >= win_xright_low) & (nonzerox < win_xright_high))\n",
    "        good_left_inds = (nonzeroy[win_y_mask & win_xleft_mask], \n",
    "                          nonzerox[win_y_mask & win_xleft_mask])\n",
    "        good_right_inds = (nonzeroy[win_y_mask & win_xright_mask], \n",
    "                          nonzerox[win_y_mask & win_xright_mask])\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### If found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(np.array(good_left_inds[1])) > minpix:\n",
    "            leftx_current = np.rint(np.mean(good_left_inds[1])).astype(int)\n",
    "        if len(np.array(good_right_inds[1])) > minpix:\n",
    "            rightx_current = np.rint(np.mean(good_right_inds[1])).astype(int)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = np.concatenate([it[1] for it in left_lane_inds])\n",
    "    lefty = np.concatenate([it[0] for it in left_lane_inds]) \n",
    "    rightx = np.concatenate([it[1] for it in right_lane_inds])\n",
    "    righty = np.concatenate([it[0] for it in right_lane_inds])\n",
    "    return leftx, lefty, rightx, righty\n",
    "\n",
    "def shade_lane(binary_warped, left_fitx_end, left_fitx_start, right_fitx_end, right_fitx_start, y_end, y_start, xm_per_pix):\n",
    "    lane_polylines = np.zeros_like(np.dstack((binary_warped, binary_warped, binary_warped)))\n",
    "    cv2.fillPoly(lane_polylines, \n",
    "                 np.array([[\n",
    "                    (left_fitx_end / xm_per_pix, y_end), \n",
    "                    (left_fitx_start / xm_per_pix, y_start), \n",
    "                    (right_fitx_start / xm_per_pix, y_start), \n",
    "                    (right_fitx_end / xm_per_pix, y_end)\n",
    "                    ]], dtype=np.int32), \n",
    "                 color=[0, 255, 0])\n",
    "    return lane_polylines\n",
    "\n",
    "# Function to plot the identified lane lines on the binary image\n",
    "def plot_polynomials(binary_warped, leftx, lefty, rightx, righty, left_fitx, right_fitx):\n",
    "    out_img = np.zeros_like(np.dstack((binary_warped, binary_warped, binary_warped)))\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    cv2.polylines(out_img, np.array([np.float32(np.stack([left_fitx, ploty], axis=1))], dtype=int), False, color=[0, 255, 0], thickness=2)\n",
    "    cv2.polylines(out_img, np.array([np.float32(np.stack([right_fitx, ploty], axis=1))], dtype=int), False, color=[0, 255, 0], thickness=2)\n",
    "\n",
    "    return out_img\n",
    "\n",
    "# Fit polynomial on the lane pixels identified from the sliding window approach\n",
    "def fit_polynomial(binary_warped, ym_per_pix = 1, xm_per_pix = 1):\n",
    "    # Find the lane pixels first\n",
    "    leftx, lefty, rightx, righty = find_lane_pixels(binary_warped)\n",
    "    ### Fit a second order polynomial to x,y in world space #####\n",
    "    left_fit = np.polyfit(ym_per_pix * np.asarray(lefty, dtype=np.int), xm_per_pix * np.asarray(leftx, dtype=np.int), 2)\n",
    "    right_fit = np.polyfit(ym_per_pix * np.asarray(righty, dtype=np.int), xm_per_pix * np.asarray(rightx, dtype=np.int), 2)\n",
    "    #print(left_fit, right_fit)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*(ploty*ym_per_pix)**2 + left_fit[1]*(ploty*ym_per_pix) + left_fit[2]\n",
    "        right_fitx = right_fit[0]*(ploty*ym_per_pix)**2 + right_fit[1]*(ploty*ym_per_pix) + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*(ploty*ym_per_pix)**2 + 1*(ploty*ym_per_pix)\n",
    "        right_fitx = 1*(ploty*ym_per_pix)**2 + 1*(ploty*ym_per_pix)\n",
    "    \n",
    "    # Find mid point of the detected lane lines in world space for offset calculation\n",
    "    midpoint_meters = (left_fitx[-1] + right_fitx[-1]) / 2\n",
    "    #print(left_fitx[-1], right_fitx[-1], midpoint_meters)\n",
    "\n",
    "    return left_fitx, right_fitx, ploty, left_fit, right_fit, midpoint_meters\n",
    "\n",
    "\n",
    "\n",
    "test_img = cv2.imread('test_images/test4.jpg')\n",
    "undist_img = undistort(test_img, mtx, dist)\n",
    "_, combined_binary = color_grad_pipeline(undist_img)\n",
    "# Read in the saved camera matrix and distortion coefficients\n",
    "perspective_pickle = pickle.load( open( \"camera_cal/perspective_pickle.p\", \"rb\" ) )\n",
    "perspective_M = perspective_pickle[\"mtxM\"]\n",
    "binary_warped = xform_perspective(combined_binary, perspective_M)\n",
    "# perspective_Minv = perspective_pickle[\"mtxMinv\"]\n",
    "left_fitx, right_fitx, ploty, _, _, _ = fit_polynomial(binary_warped)\n",
    "out_img = shade_lane(binary_warped, left_fitx[0], left_fitx[-1], \n",
    "                     right_fitx[0], right_fitx[-1], ploty[0], ploty[-1], xm_per_pix=1)\n",
    "# unwarped_polylines = xform_perspective(out_img, perspective_Minv)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 10))\n",
    "ax1.imshow(out_img)\n",
    "ax2.imshow(combined_binary) #unwarped_polylines\n",
    "ax3.imshow(binary_warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread('test_images/test5.jpg')\n",
    "undist_img = undistort(test_img, mtx, dist)\n",
    "_, combined_binary = color_grad_pipeline(undist_img)\n",
    "# Read in the saved camera matrix and distortion coefficients\n",
    "perspective_pickle = pickle.load( open( \"camera_cal/perspective_pickle.p\", \"rb\" ) )\n",
    "perspective_M = perspective_pickle[\"mtxM\"]\n",
    "binary_warped = xform_perspective(combined_binary, perspective_M)\n",
    "# perspective_Minv = perspective_pickle[\"mtxMinv\"]\n",
    "leftx, lefty, rightx, righty = find_lane_pixels(binary_warped)\n",
    "left_fitx, right_fitx, _, _, _, _ = fit_polynomial(binary_warped)\n",
    "out_img = plot_polynomials(binary_warped, leftx, lefty, rightx, righty, left_fitx, right_fitx)\n",
    "plt.figure(figsize = (60,45))\n",
    "plt.imshow(out_img)\n",
    "plt.savefig(\"output_images/test5_lane_polylines.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look ahead Filter implementation - look for lane pixel around the previous poly\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty, ym_per_pix, xm_per_pix):\n",
    "    ### Fit a second order polynomial to x,y in world space #####\n",
    "    left_fit = np.polyfit(ym_per_pix * np.asarray(lefty, dtype=np.int), xm_per_pix * np.asarray(leftx, dtype=np.int), 2)\n",
    "    right_fit = np.polyfit(ym_per_pix * np.asarray(righty, dtype=np.int), xm_per_pix * np.asarray(rightx, dtype=np.int), 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*(ploty*ym_per_pix)**2 + left_fit[1]*(ploty*ym_per_pix) + left_fit[2]\n",
    "    right_fitx = right_fit[0]*(ploty*ym_per_pix)**2 + right_fit[1]*(ploty*ym_per_pix) + right_fit[2]\n",
    "    \n",
    "    return left_fit, right_fit, left_fitx, right_fitx, ploty\n",
    "\n",
    "\n",
    "def search_around_poly(binary_warped, ym_per_pix, xm_per_pix, left_fit, right_fit):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### Set the area of search based on activated x-values within the +/- margin of our polynomial function ###\n",
    "    ### This is in pixel space. NEed the multipliers coz the polynomial coefficients are generated on points in world space\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    left_fitx = (left_fit[0]*(ploty*ym_per_pix)**2 + left_fit[1]*(ploty*ym_per_pix) + left_fit[2]) / xm_per_pix\n",
    "    right_fitx = (right_fit[0]*(ploty*ym_per_pix)**2 + right_fit[1]*(ploty*ym_per_pix) + right_fit[2]) / xm_per_pix\n",
    "\n",
    "    # print(left_fit, right_fit)\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    for i in range(len(ploty)):\n",
    "        y_mask = np.array(nonzeroy == ploty[i])\n",
    "        xleft_mask = np.array((nonzerox >= left_fitx[i] - margin) & \n",
    "                              (nonzerox < left_fitx[i] + margin))\n",
    "        xright_mask = np.array((nonzerox >= right_fitx[i] - margin) & \n",
    "                                (nonzerox < right_fitx[i] + margin))                     \n",
    "        left_lane_inds.append((nonzeroy[y_mask & xleft_mask], \n",
    "                               nonzerox[y_mask & xleft_mask]))\n",
    "        right_lane_inds.append((nonzeroy[y_mask & xright_mask], \n",
    "                                nonzerox[y_mask & xright_mask]))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = np.concatenate([it[1] for it in left_lane_inds])\n",
    "    lefty = np.concatenate([it[0] for it in left_lane_inds]) \n",
    "    rightx = np.concatenate([it[1] for it in right_lane_inds])\n",
    "    righty = np.concatenate([it[0] for it in right_lane_inds])\n",
    "    # print(len(leftx), len(lefty), len(rightx), len(righty))\n",
    "    # Fit new polynomials\n",
    "    left_fit, right_fit, left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty, ym_per_pix, xm_per_pix)\n",
    "    \n",
    "    # Find mid point of the detected lane lines in world space for offset calculation\n",
    "    midpoint_meters = (left_fitx[-1] + right_fitx[-1]) / 2\n",
    "    #print(left_fitx[-1], right_fitx[-1], midpoint_meters)\n",
    "\n",
    "    return left_fitx, right_fitx, ploty, left_fit, right_fit, midpoint_meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "## 7. Warp the detected lane boundaries back onto the original image.\n",
    "## 8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "def weighted_img(img, initial_img, α=0.8, β=1, γ=0.):\n",
    "    \"\"\"\n",
    "    initial_img * α + img * β + γ\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "\n",
    "# # This function is NOT Being used!!!\n",
    "# def overlay_transparent(background, overlay, x=0, y=0):\n",
    "\n",
    "#     background_width = background.shape[1]\n",
    "#     background_height = background.shape[0]\n",
    "\n",
    "#     if x >= background_width or y >= background_height:\n",
    "#         return background\n",
    "\n",
    "#     h, w = overlay.shape[0], overlay.shape[1]\n",
    "\n",
    "#     if x + w > background_width:\n",
    "#         w = background_width - x\n",
    "#         overlay = overlay[:, :w]\n",
    "\n",
    "#     if y + h > background_height:\n",
    "#         h = background_height - y\n",
    "#         overlay = overlay[:h]\n",
    "\n",
    "#     if overlay.shape[2] < 4:\n",
    "#         overlay = np.concatenate(\n",
    "#             [\n",
    "#                 overlay,\n",
    "#                 np.ones((overlay.shape[0], overlay.shape[1], 1), dtype = overlay.dtype) * 255\n",
    "#             ],\n",
    "#             axis = 2,\n",
    "#         )\n",
    "\n",
    "#     overlay_image = overlay[..., :3]\n",
    "#     mask = overlay[..., 3:] / (255.0 * 7)\n",
    "\n",
    "#     background[y:y+h, x:x+w] = (1.0 - mask) * background[y:y+h, x:x+w] + mask * overlay_image\n",
    "\n",
    "#     return background\n",
    "\n",
    "def measure_curvature_real(binary_warped):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Get the polynomial lines fitted on the detected lane lines\n",
    "    left_fitx, right_fitx, ploty, left_fit_cr, right_fit_cr, midpoint_meters = fit_polynomial(binary_warped, ym_per_pix, xm_per_pix)\n",
    "    lane_polylines = shade_lane(binary_warped, left_fitx[0], left_fitx[-1], \n",
    "                                right_fitx[0], right_fitx[-1], ploty[0], ploty[-1], xm_per_pix)\n",
    "\n",
    "    # Define y-value for radius of curvature measurement\n",
    "    # Choose the max y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ##### Implement the calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * ym_per_pix*y_eval + left_fit_cr[1])**2)**1.5) / (2 * left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * ym_per_pix*y_eval + right_fit_cr[1])**2)**1.5) / (2 * right_fit_cr[0])\n",
    "    \n",
    "    # Find offset = (midpoint of Image in meters - midpoint of lane in meters)  \n",
    "    offset_meters = (binary_warped.shape[1] * xm_per_pix / 2) - midpoint_meters\n",
    "    # print(binary_warped.shape[1], binary_warped.shape[1] * xm_per_pix / 2, midpoint_meters)\n",
    "    return left_fitx, right_fitx, left_curverad, right_curverad, offset_meters, lane_polylines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## End-to-end pipeline identifying the lane and overlaying it on the input image\n",
    "def run_image_pipeline(img_fname, mtx, dist, perspective_M, perspective_Minv):\n",
    "\n",
    "    input_img = cv2.imread(img_fname)\n",
    "\n",
    "    # Undistort the image\n",
    "    undistorted_img = undistort(input_img, mtx, dist)\n",
    "\n",
    "    # Apply color & gradient thresholds to get the binary image\n",
    "    _, combined_binary = color_grad_pipeline(undistorted_img)\n",
    "\n",
    "    # Apply Perspective xform\n",
    "    binary_warped = xform_perspective(combined_binary, perspective_M)\n",
    "\n",
    "    # Identify lane polylines & get the radius of curvature and offset in meters for both lane lines\n",
    "    left_fitx, right_fitx, left_curverad, right_curverad, offset_meters, lane_polylines = measure_curvature_real(binary_warped)\n",
    "\n",
    "    # Unwarp the image with lane polylines\n",
    "    unwarped_polylines = xform_perspective(lane_polylines, perspective_Minv)\n",
    "\n",
    "    # Combine the result with the original image\n",
    "    overlaid_img = cv2.addWeighted(cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB), 1, unwarped_polylines, 0.3, 0)\n",
    "    # overlaid_img = overlay_transparent(cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB), unwarped_polylines)\n",
    "\n",
    "    # Add text to the image - Take minimum of the left & right radii\n",
    "    geolocation_text = \"Radius of Curvature: {}m\".format(round(min([abs(left_curverad), abs(right_curverad)])))\n",
    "    offset_text = \"Vehicle is {} meters {} of center\".format(abs(round(offset_meters, 2)), \n",
    "                \"left\" if offset_meters > 0 else \"right\")\n",
    "    # Add text \n",
    "    overlaid_img = cv2.putText(overlaid_img, geolocation_text, (400, 50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                               1, 255, 2, cv2.LINE_AA) \n",
    "    overlaid_img = cv2.putText(overlaid_img, offset_text, (360, 100), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                               1, 255, 2, cv2.LINE_AA) \n",
    "    \n",
    "    # Display and save\n",
    "    plt.figure(figsize = (60,45))\n",
    "    plt.imshow(overlaid_img)\n",
    "    # Save the output\n",
    "    plt.savefig('output_images/{}_final.jpg'.format(fname.split('/')[-1].split('.')[0]))\n",
    "\n",
    "# Run entire pipeline on the test images\n",
    "images = glob.glob('test_images/*.jpg')\n",
    "# Read in the saved camera matrix, distortion coefficients, and perspective transform matrices\n",
    "dist_pickle = pickle.load( open( \"camera_cal/wide_dist_pickle.p\", \"rb\"))\n",
    "mtx =  dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "perspective_pickle = pickle.load( open( \"camera_cal/perspective_pickle.p\", \"rb\"))\n",
    "perspective_M = perspective_pickle[\"mtxM\"]\n",
    "perspective_Minv = perspective_pickle[\"mtxMinv\"]\n",
    "# Iterate through the test images\n",
    "for idx, fname in enumerate(images):\n",
    "    run_image_pipeline(fname, mtx, dist, perspective_M, perspective_Minv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values at the bottom of the image for the last 5 fits of the line\n",
    "        self.recent_xfitted = deque(maxlen=5) \n",
    "        # Average x values at the bottom of the image for the fitted line over the last 5 iterations\n",
    "        self.bestx = None     \n",
    "        # x values at the top of the image for the last 5 fits of the line\n",
    "        self.recent_xfitted_top = deque(maxlen=5) \n",
    "        # Average x values at the top of the image for the fitted line over the last 5 iterations\n",
    "        self.bestx_top = None     \n",
    "        # polynomial coefficients of the last 5 fits of the line\n",
    "        self.recent_fit = deque(maxlen=5) \n",
    "        #polynomial coefficients averaged over the last 5 iterations\n",
    "        self.best_fit = None  \n",
    "        # polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        # radius of curvature of the line in meters\n",
    "        self.radius_of_curvature = None \n",
    "        # distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        # difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        # x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        # y values for detected line pixels\n",
    "        self.ally = None\n",
    "        # count of consecutive failures in lane detection as per the sanity checks\n",
    "        self.failures = 0 \n",
    "        # Frame number - which frame this belongs to\n",
    "        self.current_frame = 0\n",
    "    \n",
    "## Sanity check methods - \n",
    "#  1. Checking that they have similar curvature\n",
    "def is_curvrad_similar(left_rad, right_rad, rad_thresh = 1000):\n",
    "    '''Compares the radius of curvature of left & right lane lines for similarity against a baseline threshold'''\n",
    "    return abs(left_rad - right_rad) <= rad_thresh\n",
    "\n",
    "#  2. Checking that they are separated by approximately the right distance horizontally \n",
    "def is_right_width(left_x, right_x, width_baseline = 3.0, diff_threshold = 0.2):\n",
    "    '''Compares the distance between the two lines at the bottom of the image against a baseline width = 3.7 meters & error threshold of 0.2 meters'''\n",
    "    return abs(abs(left_x - right_x) - width_baseline) <= diff_threshold\n",
    "\n",
    "#  3. Checking that they are roughly parallel\n",
    "def is_parallel(left_cr, right_cr, sec_order_thresh = 0.0006, first_order_thresh = 0.003):\n",
    "    '''Compares the two lines for being parallel against a baseline difference for second order coeff = 0.0003 & first order coeff = 0.3'''\n",
    "    return (abs(left_cr[0] - right_cr[0]) <= sec_order_thresh) & \\\n",
    "           (abs(left_cr[1] - right_cr[1]) <= first_order_thresh)\n",
    "\n",
    "\n",
    "# Function to update Line class variables once lane line identification pipeline runs\n",
    "def update_line(line, fitx, fit_cr, ploty, curverad, vehicle_dist, prev_exists, failure_count, current_frame):\n",
    "    # was the line detected in the last iteration?\n",
    "    line.detected = prev_exists\n",
    "    # x values at bottom of the image for the last 5 fits of the line\n",
    "    line.recent_xfitted.append(fitx[-1]) \n",
    "    # average x values at bottom of the image for the fitted line over the last 5 iterations\n",
    "    line.bestx = np.mean(line.recent_xfitted, dtype=type(line.recent_xfitted[0]))     \n",
    "    # x values at top of the image for the last 5 fits of the line\n",
    "    line.recent_xfitted_top.append(fitx[0]) \n",
    "    #average x values of the fitted line over the last 5 iterations\n",
    "    line.bestx_top = np.mean(line.recent_xfitted_top, dtype=type(line.recent_xfitted_top[0]))     \n",
    "    # polynomial coefficients of the last 5 fits of the line\n",
    "    line.recent_fit.append(fit_cr) \n",
    "    # polynomial coefficients averaged over the last 5 iterations\n",
    "    line.best_fit = np.mean(line.recent_fit, axis=1)\n",
    "    # polynomial coefficients for the most recent fit\n",
    "    line.current_fit = fit_cr  \n",
    "    # radius of curvature of the line in meters\n",
    "    line.radius_of_curvature = curverad\n",
    "    # distance in meters of vehicle center from the line\n",
    "    line.line_base_pos = vehicle_dist \n",
    "    # difference in fit coefficients between last and new fits\n",
    "    line.diffs = np.array([0,0,0], dtype='float') if len(line.recent_fit) < 2 else  list(map(sub, line.recent_fit[-1], line.recent_fit[-2]))\n",
    "    # x values for detected line pixels\n",
    "    line.allx = fitx \n",
    "    # y values for detected line pixels\n",
    "    line.ally = ploty\n",
    "    # count of consecutive failures in lane detection as per the sanity checks\n",
    "    line.failures = failure_count \n",
    "    # Frame number - which frame this belongs to\n",
    "    line.current_frame = current_frame\n",
    "\n",
    "# Function to increment the variable failures when the sanity check fails\n",
    "def increment_failure(line, failure_count, current_frame):\n",
    "    line.failures = failure_count\n",
    "    line.current_frame = current_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## End-to-end pipeline for video feed identifying the lane and overlaying it on each frame\n",
    "def get_frame_lanes(binary_warped, isFirstFrame, left_fit=None, right_fit=None):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Get the polynomial lines fitted on the detected lane lines\n",
    "    if isFirstFrame:\n",
    "        # Call the function that implements sliding window approach\n",
    "        left_fitx, right_fitx, ploty, left_fit_cr, right_fit_cr, midpoint_meters = fit_polynomial(binary_warped, ym_per_pix, xm_per_pix)\n",
    "    else:\n",
    "        # Call the function with Look ahead implementation\n",
    "        left_fitx, right_fitx, ploty, left_fit_cr, right_fit_cr, midpoint_meters = search_around_poly(binary_warped, ym_per_pix, xm_per_pix, left_fit, right_fit)    \n",
    "    # Define y-value for radius of curvature measurement\n",
    "    # Choose the max y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    ##### Implement the calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * ym_per_pix*y_eval + left_fit_cr[1])**2)**1.5) / (2 * left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * ym_per_pix*y_eval + right_fit_cr[1])**2)**1.5) / (2 * right_fit_cr[0])\n",
    "    \n",
    "    # Find offset = (midpoint of Image in meters - midpoint of lane in meters)  \n",
    "    offset_meters = (binary_warped.shape[1] * xm_per_pix / 2) - midpoint_meters\n",
    "    # print(binary_warped.shape[1], binary_warped.shape[1] * xm_per_pix / 2, midpoint_meters)\n",
    "    return left_fitx, right_fitx, left_fit_cr, right_fit_cr, left_curverad, right_curverad, offset_meters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_frame_pipeline(input_frame, mtx, dist, perspective_M, perspective_Minv, left_lane, right_lane):\n",
    "    # Convert the RGB image to BGR\n",
    "    input_img = cv2.cvtColor(input_frame, cv2.COLOR_RGB2BGR)\n",
    "    # Undistort the image\n",
    "    undistorted_img = undistort(input_img, mtx, dist)\n",
    "\n",
    "    # Apply color & gradient thresholds to get the binary image\n",
    "    _, combined_binary = color_grad_pipeline(undistorted_img)\n",
    "\n",
    "    # Apply Perspective xform\n",
    "    binary_warped = xform_perspective(combined_binary, perspective_M)\n",
    "\n",
    "    # Defining the coeff of transformation for x dimension from pixel space to world space\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    # define y points\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "\n",
    "    # get the cumulative value of failure_count until last frame from any of the lane objects\n",
    "    failure_count = left_lane.failures\n",
    "    # print(failure_count)\n",
    "\n",
    "    # get the previous frame number from any of the lane objects\n",
    "    current_frame = left_lane.current_frame \n",
    "    isFirstFrame = (current_frame == 0)\n",
    "\n",
    "    # Identify lane polylines & get the radius of curvature and offset in meters for both lane lines\n",
    "    if isFirstFrame or failure_count > 3: # either the first frame or the lane detection has failed 3 times consecutively\n",
    "        # get_frame_lanes Function takes only the image. Doesn't need the polynomial coeffs. from the prev fit.\n",
    "        left_fitx, right_fitx, left_fit_cr, right_fit_cr, left_curverad, right_curverad, \\\n",
    "        offset_meters = get_frame_lanes(binary_warped, True) \n",
    "        # print(left_fitx[-1], right_fitx[-1], left_fit_cr, right_fit_cr)\n",
    "        # Calculate distance of vehicle center from the lane line\n",
    "        lane_center = (left_fitx[-1] + right_fitx[-1]) / 2\n",
    "        vehicle_dist_left = lane_center + offset_meters - left_fitx[-1]\n",
    "        vehicle_dist_right = right_fitx[-1] - lane_center - offset_meters\n",
    "        # Sanity check on the detected lane lines\n",
    "        sanity_checked = is_right_width(left_fitx[-1], right_fitx[-1], width_baseline = 3.0, diff_threshold = 0.4) & \\\n",
    "                         is_parallel(left_fit_cr, right_fit_cr, sec_order_thresh = 0.0009, first_order_thresh = 0.03)\n",
    "                         #is_curvrad_similar(left_curverad, right_curverad, rad_thresh = 5000) & \\\n",
    "                         \n",
    "        # print(sanity_checked)\n",
    "        if isFirstFrame or sanity_checked:\n",
    "            # lines are good. Update the variables of the Line objects. Failures variable to be reset to zero.\n",
    "            update_line(left_lane, left_fitx, left_fit_cr, ploty, left_curverad, vehicle_dist_left, False, 0, current_frame + 1)\n",
    "            update_line(right_lane, right_fitx, right_fit_cr, ploty, right_curverad, vehicle_dist_right, False, 0, current_frame + 1)\n",
    "            # lines are good. Use the average of last 5 iterations' x location & polynomial coeffs.\n",
    "            # This is for smoothening out the identified lanes\n",
    "            lane_polylines = shade_lane(binary_warped, left_lane.bestx_top, left_lane.bestx, right_lane.bestx_top, \\\n",
    "                                        right_lane.bestx, ploty[0], ploty[-1], xm_per_pix)\n",
    "        else:\n",
    "            # Need to use previous lines' parameters & increment failure_count\n",
    "            # Use the average of previous 5 iterations' x location & polynomial coeffs. This is for smoothening out the identified lanes\n",
    "            lane_polylines = shade_lane(binary_warped, left_lane.bestx_top, left_lane.bestx, right_lane.bestx_top, \\\n",
    "                                        right_lane.bestx, ploty[0], ploty[-1], xm_per_pix)\n",
    "            # Increment failure count & frame number for both lane objects\n",
    "            increment_failure(left_lane, failure_count + 1, current_frame + 1)\n",
    "            increment_failure(right_lane, failure_count + 1, current_frame + 1)\n",
    "\n",
    "    else:\n",
    "        # get_frame_lanes Function takes the image + the polynomial coeffs. from the prev fit.\n",
    "        left_fitx, right_fitx, left_fit_cr, right_fit_cr, left_curverad, right_curverad, \\\n",
    "        offset_meters = get_frame_lanes(binary_warped, isFirstFrame, left_lane.current_fit, right_lane.current_fit)\n",
    "        # Calculate distance of vehicle center from the lane line\n",
    "        lane_center = (left_fitx[-1] + right_fitx[-1]) / 2\n",
    "        vehicle_dist_left = lane_center + offset_meters - left_fitx[-1]\n",
    "        vehicle_dist_right = right_fitx[-1] - lane_center - offset_meters\n",
    "        # print(left_fitx[-1], right_fitx[-1], left_fit_cr, right_fit_cr)\n",
    "        # Sanity check on the detected lane lines\n",
    "        sanity_checked = is_right_width(left_fitx[-1], right_fitx[-1], width_baseline = 3.0, diff_threshold = 0.4) & \\\n",
    "                         is_parallel(left_fit_cr, right_fit_cr, sec_order_thresh = 0.0009, first_order_thresh = 0.03)\n",
    "                         #is_curvrad_similar(left_curverad, right_curverad, rad_thresh = 5000) & \\\n",
    "                         \n",
    "        # print(sanity_checked)\n",
    "        if sanity_checked:\n",
    "            # lines are good. update the variables of the line objects. Failures variable to be reset to zero.\n",
    "            update_line(left_lane, left_fitx, left_fit_cr, ploty, left_curverad, vehicle_dist_left, \\\n",
    "                       (left_lane.failures == 0), 0, current_frame + 1)\n",
    "            update_line(right_lane, right_fitx, right_fit_cr, ploty, right_curverad, vehicle_dist_right, \\\n",
    "                       (right_lane.failures == 0), 0, current_frame + 1)\n",
    "            # lines are good. Use the average of last 5 iterations' x location & polynomial coeffs.\n",
    "            # This is for smoothening out the identified lanes\n",
    "            lane_polylines = shade_lane(binary_warped, left_lane.bestx_top, left_lane.bestx, right_lane.bestx_top, \\\n",
    "                                        right_lane.bestx, ploty[0], ploty[-1], xm_per_pix)\n",
    "        else:\n",
    "            # Need to use previous lines' parameters & increment failure_count\n",
    "            # Use the average of previous 5 iterations' x location & polynomial coeffs. This is for smoothening out the identified lanes\n",
    "            lane_polylines = shade_lane(binary_warped, left_lane.bestx_top, left_lane.bestx, right_lane.bestx_top, \\\n",
    "                                        right_lane.bestx, ploty[0], ploty[-1], xm_per_pix)\n",
    "            # Increment failure count & frame number for both lane objects\n",
    "            increment_failure(left_lane, failure_count + 1, current_frame + 1)\n",
    "            increment_failure(right_lane, failure_count + 1, current_frame + 1)\n",
    "\n",
    "    # Unwarp the image with lane polylines\n",
    "    unwarped_polylines = xform_perspective(lane_polylines, perspective_Minv)\n",
    "\n",
    "    # Combine the result with the original image\n",
    "    overlaid_img = cv2.addWeighted(input_frame, 1, unwarped_polylines, 0.3, 0)\n",
    "    # overlay_transparent(input_frame, unwarped_polylines)\n",
    "\n",
    "    # Add text to the image - Radii of curvature & offset\n",
    "    geolocation_text = \"Radius of Curvature - Left: {}m, Right: {}m\".format(round(abs(left_curverad)), round(abs(right_curverad)))\n",
    "    offset_text = \"Vehicle is {} meters {} of center\".format(abs(round(offset_meters, 2)), \n",
    "                \"left\" if offset_meters > 0 else \"right\")\n",
    "    # Add text \n",
    "    overlaid_img = cv2.putText(overlaid_img, geolocation_text, (260, 50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                               1, 255, 2, cv2.LINE_AA) \n",
    "    overlaid_img = cv2.putText(overlaid_img, offset_text, (360, 100), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                               1, 255, 2, cv2.LINE_AA) \n",
    "\n",
    "    return overlaid_img\n",
    "\n",
    "# Wrapper function for VideoFileClip.fl_image\n",
    "def process_frame(frame):\n",
    "    return run_frame_pipeline(frame, mtx, dist, perspective_M, perspective_Minv, left_lane, right_lane)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running the entire pipeline on video input\n",
    "try:\n",
    "    dist_pickle, perspective_pickle    \n",
    "except NameError:\n",
    "    # Read in the saved camera matrix, distortion coefficients, and perspective transform matrices\n",
    "    dist_pickle = pickle.load( open( \"camera_cal/wide_dist_pickle.p\", \"rb\"))\n",
    "    mtx =  dist_pickle[\"mtx\"]\n",
    "    dist = dist_pickle[\"dist\"]\n",
    "    perspective_pickle = pickle.load( open( \"camera_cal/perspective_pickle.p\", \"rb\"))\n",
    "    perspective_M = perspective_pickle[\"mtxM\"]\n",
    "    perspective_Minv = perspective_pickle[\"mtxMinv\"]\n",
    "# Instantiate the left and right lane classes\n",
    "left_lane = Line()\n",
    "right_lane = Line()\n",
    "\n",
    "project_output = 'test_videos_output/project_video.mp4'\n",
    "vid_clip = VideoFileClip(\"project_video.mp4\") #.subclip(37,41)\n",
    "# Run the lane finding algo on every frame in the clip\n",
    "processed_clip = vid_clip.fl_image(process_frame)\n",
    "%time processed_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the entire pipeline on challenge video input\n",
    "try:\n",
    "    dist_pickle, perspective_pickle    \n",
    "except NameError:\n",
    "    # Read in the saved camera matrix, distortion coefficients, and perspective transform matrices\n",
    "    dist_pickle = pickle.load( open( \"camera_cal/wide_dist_pickle.p\", \"rb\"))\n",
    "    mtx =  dist_pickle[\"mtx\"]\n",
    "    dist = dist_pickle[\"dist\"]\n",
    "    perspective_pickle = pickle.load( open( \"camera_cal/perspective_pickle.p\", \"rb\"))\n",
    "    perspective_M = perspective_pickle[\"mtxM\"]\n",
    "    perspective_Minv = perspective_pickle[\"mtxMinv\"]\n",
    "# Instantiate the left and right lane classes\n",
    "left_lane = Line()\n",
    "right_lane = Line()\n",
    "\n",
    "challenge_output = 'test_videos_output/challenge_video.mp4'\n",
    "vid_clip = VideoFileClip(\"challenge_video.mp4\") #.subclip(0,5)\n",
    "# Run the lane finding algo on every frame in the clip\n",
    "processed_clip = vid_clip.fl_image(process_frame)\n",
    "%time processed_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the entire pipeline on harder challenge video input\n",
    "try:\n",
    "    dist_pickle, perspective_pickle    \n",
    "except NameError:\n",
    "    # Read in the saved camera matrix, distortion coefficients, and perspective transform matrices\n",
    "    dist_pickle = pickle.load( open( \"camera_cal/wide_dist_pickle.p\", \"rb\"))\n",
    "    mtx =  dist_pickle[\"mtx\"]\n",
    "    dist = dist_pickle[\"dist\"]\n",
    "    perspective_pickle = pickle.load( open( \"camera_cal/perspective_pickle.p\", \"rb\"))\n",
    "    perspective_M = perspective_pickle[\"mtxM\"]\n",
    "    perspective_Minv = perspective_pickle[\"mtxMinv\"]\n",
    "# Instantiate the left and right lane classes\n",
    "left_lane = Line()\n",
    "right_lane = Line()\n",
    "\n",
    "challenge_output_2 = 'test_videos_output/harder_challenge_video.mp4'\n",
    "vid_clip = VideoFileClip(\"harder_challenge_video.mp4\") #.subclip(0,5)\n",
    "# Run the lane finding algo on every frame in the clip\n",
    "processed_clip = vid_clip.fl_image(process_frame)\n",
    "%time processed_clip.write_videofile(challenge_output_2, audio=False)"
   ]
  }
 ]
}